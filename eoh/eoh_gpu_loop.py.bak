import os, re, io, json, time, math, textwrap, argparse, random
from typing import Optional, Callable, List, Dict, Any, Tuple
import numpy as np
import pandas as pd

# Data sources
import requests
try:
    import yfinance as yf
    _HAS_YF = True
except Exception:
    _HAS_YF = False

# Backtesting
from backtesting import Backtest, Strategy
from backtesting.lib import SMA, RSI, crossover

# HF Transformers
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

# -------------------------
# args
# -------------------------
def get_args():
    ap = argparse.ArgumentParser()
    ap.add_argument("--model-dir", required=True, help="HF local model dir")
    ap.add_argument("--symbol", default="SPY")
    ap.add_argument("--train_start", required=True)
    ap.add_argument("--train_end", required=True)
    ap.add_argument("--test_start", required=True)
    ap.add_argument("--test_end", required=True)
    ap.add_argument("--generations", type=int, default=1)
    ap.add_argument("--population", type=int, default=8)
    ap.add_argument("--commission", type=float, default=0.0005)
    ap.add_argument("--cpus", type=int, default=8)
    ap.add_argument("--outdir", required=True)
    ap.add_argument("--max_new_tokens", type=int, default=320)
    ap.add_argument("--temperature", type=float, default=0.7)
    ap.add_argument("--seed", type=int, default=42)
    return ap.parse_args()

# -------------------------
# utils
# -------------------------
def log(*a): print(*a, flush=True)

def ensure_outdir(d):
    os.makedirs(d, exist_ok=True)

def save_text(path: str, txt: str):
    with open(path, "w", encoding="utf-8") as f: f.write(txt)

def df_ohlcv(df: pd.DataFrame) -> pd.DataFrame:
    """Ensure OHLCV columns & Date index."""
    cols = {c.lower(): c for c in df.columns}
    def pick(name):
        ln = name.lower()
        if ln in cols: return cols[ln]
        # try any alias
        for c in df.columns:
            if c.lower() == ln: return c
        return None
    mapping = {}
    for lo, Hi in [("open","Open"),("high","High"),("low","Low"),("close","Close"),("volume","Volume")]:
        c = pick(lo)
        if c is not None: mapping[c] = Hi
    if mapping:
        df = df.rename(columns=mapping)
    # Date column / index
    if "Date" in df.columns:
        df["Date"] = pd.to_datetime(df["Date"])
        df = df.set_index("Date").sort_index()
    elif "timestamp" in df.columns:
        df["Date"] = pd.to_datetime(df["timestamp"])
        df = df.set_index("Date").sort_index()
    else:
        # assume index is date-like
        df = df.copy()
        if not isinstance(df.index, pd.DatetimeIndex):
            df.index = pd.to_datetime(df.index)
        df.index.name = "Date"
    # only keep required cols
    for need in ["Open","High","Low","Close","Volume"]:
        if need not in df.columns:
            # fill if missing (Volume often missing)
            if need == "Volume":
                df[need] = 0
            else:
                raise ValueError(f"Missing column: {need}")
    return df[["Open","High","Low","Close","Volume"]]

def slice_df(df: pd.DataFrame, start: str, end: str) -> pd.DataFrame:
    return df.loc[(df.index >= pd.to_datetime(start)) & (df.index <= pd.to_datetime(end))].copy()

# -------------------------
# Local CSV (priority)
# -------------------------
PRICE_CACHE_ROOT = "/root/autodl-tmp/price_cache"

def load_local_csv(symbol: str, start: str, end: str) -> Optional[pd.DataFrame]:
    path = os.path.join(PRICE_CACHE_ROOT, f"{symbol}_2020_2023.csv")
    if not os.path.exists(path):
        return None
    try:
        df = pd.read_csv(path)
        # robust columns
        if "timestamp" in df.columns and "Date" not in df.columns:
            df["Date"] = pd.to_datetime(df["timestamp"])
        elif "Date" in df.columns:
            df["Date"] = pd.to_datetime(df["Date"])
        else:
            # some CSVs might have lowercase 'date'
            if "date" in df.columns:
                df["Date"] = pd.to_datetime(df["date"])
            else:
                raise ValueError("No Date/timestamp column in local CSV")
        df = df_ohlcv(df)
        df = slice_df(df, start, end)
        if len(df) == 0:
            return None
        log(f"[INFO] local CSV hit: {path} rows={len(df)}")
        return df
    except Exception as e:
        log(f"[WARN] local CSV load failed: {e}")
        return None

# -------------------------
# Alpha Vantage (CSV)
# -------------------------
def load_alpha(symbol: str, start: str, end: str) -> Optional[pd.DataFrame]:
    key = os.environ.get("ALPHA_VANTAGE_API_KEY","").strip()
    if not key:
        log("[WARN] ALPHA key missing")
        return None
    url = "https://www.alphavantage.co/query"
    params = dict(function="TIME_SERIES_DAILY", symbol=symbol, apikey=key, datatype="csv", outputsize="full")
    try:
        r = requests.get(url, params=params, timeout=30)
        ct = r.headers.get("Content-Type","")
        if (ct and "text/csv" in ct) or (r.text and r.text.strip().startswith("timestamp")):
            df = pd.read_csv(io.StringIO(r.text))
            df = df.rename(columns={"timestamp":"Date"})
            df = df_ohlcv(df)
            df = slice_df(df, start, end)
            if len(df)==0: return None
            log(f"[INFO] alpha CSV rows={len(df)}")
            return df
        else:
            # Typically rate limited or premium endpoint
            log("[WARN] Alpha responded non-CSV (likely rate-limited/premium)")
            return None
    except Exception as e:
        log(f"[WARN] alpha error: {e}")
        return None

# -------------------------
# yfinance
# -------------------------
def load_yf(symbol: str, start: str, end: str) -> Optional[pd.DataFrame]:
    if not _HAS_YF:
        return None
    try:
        df = yf.download(symbol, start=start, end=end, progress=False, auto_adjust=False, interval="1d")
        if isinstance(df, pd.DataFrame) and len(df):
            df = df.rename(columns={"Adj Close":"Close"})
            df = df_ohlcv(df)
            log(f"[INFO] yfinance rows={len(df)}")
            return df
        return None
    except Exception as e:
        log(f"[WARN] yfinance error: {e}")
        return None

# -------------------------
# Synthetic
# -------------------------
def make_synth(symbol: str, start: str, end: str) -> pd.DataFrame:
    idx = pd.date_range(start=start, end=end, freq="B")
    px = 100.0
    opn=[]; hi=[]; lo=[]; cls=[]; vol=[]
    rng = np.random.default_rng(42)
    for _ in range(len(idx)):
        ret = rng.normal(0, 0.01)
        px = max(1.0, px * (1+ret))
        c = px
        o = c*(1+rng.normal(0,0.002))
        h = max(o,c)*(1+abs(rng.normal(0,0.003)))
        l = min(o,c)*(1-abs(rng.normal(0,0.003)))
        v = int(abs(rng.normal(1e6, 2e5)))
        opn.append(o); hi.append(h); lo.append(l); cls.append(c); vol.append(v)
    df = pd.DataFrame({"Open":opn,"High":hi,"Low":lo,"Close":cls,"Volume":vol}, index=idx)
    df.index.name="Date"
    log(f"[INFO] synthetic rows={len(df)}")
    return df

# -------------------------
# Unified loader (local -> alpha -> yf -> synth)
# -------------------------
def load_prices(symbol: str, start: str, end: str) -> pd.DataFrame:
    for fn in (load_local_csv, load_alpha, load_yf):
        df = fn(symbol, start, end)
        if df is not None and len(df):
            return df
    log("[WARN] Falling back to synthetic")
    return make_synth(symbol, start, end)

# -------------------------
# LLM
# -------------------------
SYSTEM_PROMPT = """You are an expert quantitative strategist. 
Output ONLY a Python code block that defines a Backtesting.py Strategy named `Strat`.
Rules:
- Use only: numpy, pandas, from backtesting import Strategy; from backtesting.lib import SMA, RSI, crossover
- Avoid external imports / I/O.
- Indicators must be created via self.I(...)
- Provide class parameters as class variables (e.g., n1=10).
- Buy/sell in next() using crossover(...) or simple comparisons.
- No plotting, no print.
- Keep code short and runnable.
"""

# 注意：这里只替换 {SYMBOL}，其他花括号都已用双括号转义，避免 .format() 误替换
USER_TASK_TMPL = """Design a simple rule-based trading strategy for {SYMBOL} daily OHLCV data.
Constraints:
- Define `class Strat(Strategy):` with parameters and init/next methods.
- Example patterns allowed: SMA cross, RSI thresholds, Bollinger-like via SMA +/- k*std (you can code std via self.I or rolling).
- Commission is handled externally; you don't need to apply it.
Return ONLY code wrapped in a Python code block like:
```python
# your code here
```"""

def extract_code(txt: str) -> Optional[str]:
    m = re.findall(r"```(?:python)?\s*(.+?)```", txt, flags=re.S|re.I)
    if m:
        return m[0].strip()
    # fallback: if no fence, try everything
    return txt.strip() if "class Strat" in txt else None

def build_messages(prompt: str) -> List[Dict[str,str]]:
    return [
        {"role":"system","content":SYSTEM_PROMPT},
        {"role":"user","content":prompt}
    ]

def chat_once(tok, mdl, prompt: str, max_new_tokens=320, temperature=0.7) -> str:
    msgs = build_messages(prompt)
    # 先用模板得到纯文本，再二次 tokenizer，确保 attention_mask 存在
    text = tok.apply_chat_template(msgs, add_generation_prompt=True, tokenize=False)
    enc  = tok(text, return_tensors="pt")
    enc  = {k:v.to(mdl.device) for k,v in enc.items()}
    eot  = tok.eos_token_id
    out  = mdl.generate(
        **enc,
        max_new_tokens=max_new_tokens,
        do_sample=True,
        temperature=float(temperature),
        eos_token_id=eot,
        pad_token_id=eot,
    )
    new_tokens = out[0, enc["input_ids"].shape[1]:]
    return tok.decode(new_tokens, skip_special_tokens=True)

# -------------------------
# Strategy sandbox
# -------------------------
ALLOWED_GLOBALS = {
    "__builtins__": {
        "abs": abs, "min": min, "max": max, "range": range, "len": len, "sum": sum, "any": any, "all": all, "round": round
    },
    "np": np, "numpy": np,
    "pd": pd, "pandas": pd,
    "Strategy": Strategy,
    "SMA": SMA, "RSI": RSI, "crossover": crossover,
}

def safe_exec_strategy(code: str) -> Optional[Callable]:
    """Exec code and return Strat class if valid."""
    try:
        loc: Dict[str,Any] = {}
        exec(compile(code, "<llm_code>", "exec"), ALLOWED_GLOBALS, loc)
        Strat = loc.get("Strat", None)
        if Strat is None:
            return None
        # quick shape check
        if not hasattr(Strat, "init") or not hasattr(Strat, "next"):
            return None
        return Strat
    except Exception as e:
        log(f"[WARN] exec failed: {e}")
        return None

# -------------------------
# Evaluation
# -------------------------
def run_bt(df: pd.DataFrame, Strat: Strategy, commission: float) -> Tuple[pd.Series, Backtest]:
    bt = Backtest(df, Strat, cash=100_000, commission=commission, exclusive_orders=True)
    stats = bt.run()  # 不传 finalize_trades=True，避免不同版本冲突
    return stats, bt

def fitness_from_stats(st: pd.Series) -> float:
    # 简单打分：年化收益/回撤（若缺失则降级处理）
    r = float(st.get("Return [%]", 0.0))
    dd = float(st.get("Max. Drawdown [%]", 1.0))
    sharpe = float(st.get("Sharpe Ratio", 0.0))
    # 惩罚大回撤；奖励正夏普
    f = r - 0.5*max(0.0, dd) + 10.0*max(0.0, sharpe)
    return f

# -------------------------
# Main
# -------------------------
def main():
    args = get_args()
    random.seed(args.seed); np.random.seed(args.seed)
    ensure_outdir(args.outdir)

    # 载入行情（本地优先）
    # 为确保覆盖 train/test，统一按全区间加载
    span_start = min(args.train_start, args.test_start)
    span_end   = max(args.train_end, args.test_end)
    df_all = load_prices(args.symbol, span_start, span_end)
    df_train = slice_df(df_all, args.train_start, args.train_end)
    df_test  = slice_df(df_all, args.test_start,  args.test_end)
    log(f"[INFO] split: train={len(df_train)} test={len(df_test)}")

    # LLM
    tok = AutoTokenizer.from_pretrained(args.model_dir, use_fast=True, trust_remote_code=True)
    mdl = AutoModelForCausalLM.from_pretrained(
        args.model_dir, device_map="auto", dtype=torch.bfloat16, trust_remote_code=True
    )
    log(f"[INFO] model loaded on {mdl.device}")

    # 生成初始种群
    prompts = []
    for i in range(args.population):
        prompts.append(USER_TASK_TMPL.format(SYMBOL=args.symbol))

    gen_dir = os.path.join(args.outdir, "gen01_codes")
    ensure_outdir(gen_dir)
    rows = []

    for i, pr in enumerate(prompts, 1):
        log(f"[GEN] {i}/{len(prompts)}")
        txt  = chat_once(tok, mdl, pr, max_new_tokens=args.max_new_tokens, temperature=args.temperature)
        code = extract_code(txt)
        if not code:
            log("[WARN] no code extracted")
            continue
        Strat = safe_exec_strategy(code)
        if Strat is None:
            log("[WARN] no valid Strat class")
            continue

        # 回测（只在训练集打分；也额外记录测试集表现）
        try:
            st_train, _ = run_bt(df_train, Strat, args.commission)
            st_test, _  = run_bt(df_test,  Strat, args.commission)
            fit = fitness_from_stats(st_train)
            code_path = os.path.join(gen_dir, f"strat_{i:03d}.py")
            save_text(code_path, code)
            row = {
                "id": i,
                "fitness": fit,
                "train_Return_%": float(st_train.get("Return [%]", float("nan"))),
                "train_Sharpe": float(st_train.get("Sharpe Ratio", float("nan"))),
                "train_MaxDD_%": float(st_train.get("Max. Drawdown [%]", float("nan"))),
                "test_Return_%": float(st_test.get("Return [%]", float("nan"))),
                "test_Sharpe": float(st_test.get("Sharpe Ratio", float("nan"))),
                "test_MaxDD_%": float(st_test.get("Max. Drawdown [%]", float("nan"))),
                "code_path": code_path
            }
            rows.append(row)
            log(f"[OK] id={i} fit={fit:.2f} trainR={row['train_Return_%']:.2f} testR={row['test_Return_%']:.2f}")
        except Exception as e:
            log(f"[WARN] backtest failed: {e}")
            continue

    if not rows:
        log("[INFO] generation 1 done, valid=0")
        return

    # 保存这一代结果
    df_res = pd.DataFrame(rows).sort_values("fitness", ascending=False)
    df_res.to_csv(os.path.join(args.outdir, "gen01.csv"), index=False)
    best = df_res.iloc[0].to_dict()
    save_text(os.path.join(args.outdir, "best_strategy.py"), open(best["code_path"], "r", encoding="utf-8").read())
    save_text(os.path.join(args.outdir, "best_metrics.json"), json.dumps(best, indent=2, ensure_ascii=False))
    save_text(os.path.join(args.outdir, "README.txt"), textwrap.dedent(f"""
    symbol: {args.symbol}
    train: {args.train_start} ~ {args.train_end}
    test : {args.test_start} ~ {args.test_end}
    population: {args.population}
    generations: {args.generations} (this demo generates 1st gen only)
    commission: {args.commission}
    files:
      - gen01.csv
      - gen01_codes/
      - best_strategy.py
      - best_metrics.json
    """).strip())

    log(f"[INFO] generation 1 done, valid={len(df_res)}; best fitness={best['fitness']:.2f}")
    log(f"[INFO] results -> {args.outdir}")

if __name__ == "__main__":
    main()